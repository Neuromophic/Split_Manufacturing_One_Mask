{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b410ea6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import config\n",
    "import os\n",
    "import numpy as np\n",
    "import evaluation as E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a8455cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading acuteinflammation 6 2 184 61 25\n",
      "Loading acutenephritis 6 2 184 61 25\n",
      "Loading balancescale 4 3 184 61 126\n",
      "Loading blood 4 2 184 61 150\n",
      "Loading breastcancer 9 2 184 61 58\n",
      "Loading breastcancerwisc 9 2 184 61 140\n",
      "Loading breasttissue 9 6 184 61 22\n",
      "Loading ecoli 7 8 184 61 68\n",
      "Loading energyy1 8 3 184 61 154\n",
      "Loading energyy2 8 3 184 61 154\n",
      "Loading fertility 9 2 184 61 21\n",
      "Loading glass 9 6 184 61 43\n",
      "Loading habermansurvival 3 2 184 61 62\n",
      "Loading hayesroth 3 3 184 61 32\n",
      "Loading ilpdindianliver 9 2 184 61 117\n",
      "Loading iris 4 3 184 61 31\n",
      "Loading mammographic 5 2 184 61 193\n",
      "Loading monks1 6 2 184 61 111\n",
      "Loading monks2 6 2 184 61 120\n",
      "Loading monks3 6 2 184 61 110\n",
      "Loading pima 8 2 184 61 154\n",
      "Loading pittsburgbridgesMATERIAL 7 3 184 61 22\n",
      "Loading pittsburgbridgesRELL 7 3 184 61 21\n",
      "Loading pittsburgbridgesSPAN 7 3 184 61 18\n",
      "Loading pittsburgbridgesTORD 7 2 184 61 20\n",
      "Loading pittsburgbridgesTYPE 7 6 184 61 22\n",
      "Loading postoperative 8 3 184 61 19\n",
      "Loading seeds 7 3 184 61 43\n",
      "Loading teaching 5 3 184 61 31\n",
      "Loading tictactoe 9 2 184 61 192\n",
      "Loading vertebralcolumn2clases 6 2 184 61 63\n",
      "Loading vertebralcolumn3clases 6 3 184 61 63\n",
      "Finish data loading.\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "device = config.device\n",
    "# device = torch.device('cuda:0')\n",
    "# device = 'cpu'\n",
    "\n",
    "# Prepare data\n",
    "## Datasets\n",
    "datasets = os.listdir('./Datasets/datasets/')\n",
    "datasets = [d for d in datasets if d.endswith('.p')]\n",
    "datasets.sort()\n",
    "\n",
    "## Load data\n",
    "names   = []\n",
    "num_in  = []\n",
    "num_out = []\n",
    "X_trains = []\n",
    "y_trains = []\n",
    "X_valids = []\n",
    "y_valids = []\n",
    "X_tests = []\n",
    "y_tests = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    datapath = os.path.join('./Datasets/datasets/' + dataset)\n",
    "    with open(datapath, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    X_test     = data['X_test']\n",
    "    y_test     = data['y_test']\n",
    "    data_name  = data['name']\n",
    "\n",
    "    N_class    = data['n_class']\n",
    "    N_feature  = data['n_feature']\n",
    "    N_train    = X_train.shape[0]\n",
    "    N_valid    = X_valid.shape[0]\n",
    "    N_test     = X_test.shape[0]\n",
    "    \n",
    "    print('Loading', data_name, N_feature, N_class, N_train, N_valid, N_test)\n",
    "    \n",
    "    names.append(data_name)\n",
    "    num_in.append(N_feature)\n",
    "    num_out.append(N_class)\n",
    "    \n",
    "    X_tests.append(X_test.to(device))\n",
    "    y_tests.append(y_test.to(device))\n",
    "\n",
    "print('Finish data loading.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d3f4409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spnn_False_0.001_0',\n",
       " 'spnn_False_0.001_1',\n",
       " 'spnn_False_0.001_2',\n",
       " 'spnn_False_0.001_3',\n",
       " 'spnn_False_0.001_4',\n",
       " 'spnn_False_0.001_5',\n",
       " 'spnn_False_0.001_6',\n",
       " 'spnn_False_0.001_7',\n",
       " 'spnn_False_0.001_8',\n",
       " 'spnn_False_0.001_9',\n",
       " 'spnn_False_0.01_0',\n",
       " 'spnn_False_0.01_1',\n",
       " 'spnn_False_0.01_2',\n",
       " 'spnn_False_0.01_3',\n",
       " 'spnn_False_0.01_4',\n",
       " 'spnn_False_0.01_5',\n",
       " 'spnn_False_0.01_6',\n",
       " 'spnn_False_0.01_7',\n",
       " 'spnn_False_0.01_8',\n",
       " 'spnn_False_0.01_9',\n",
       " 'spnn_False_0.1_0',\n",
       " 'spnn_False_0.1_1',\n",
       " 'spnn_False_0.1_2',\n",
       " 'spnn_False_0.1_3',\n",
       " 'spnn_False_0.1_4',\n",
       " 'spnn_False_0.1_5',\n",
       " 'spnn_False_0.1_6',\n",
       " 'spnn_False_0.1_7',\n",
       " 'spnn_False_0.1_8',\n",
       " 'spnn_False_0.1_9',\n",
       " 'spnn_False_0.2_0',\n",
       " 'spnn_False_0.2_1',\n",
       " 'spnn_False_0.2_2',\n",
       " 'spnn_False_0.2_3',\n",
       " 'spnn_False_0.2_4',\n",
       " 'spnn_False_0.2_5',\n",
       " 'spnn_False_0.2_6',\n",
       " 'spnn_False_0.2_7',\n",
       " 'spnn_False_0.2_8',\n",
       " 'spnn_False_0.2_9',\n",
       " 'spnn_False_0.5_0',\n",
       " 'spnn_False_0.5_1',\n",
       " 'spnn_False_0.5_2',\n",
       " 'spnn_False_0.5_3',\n",
       " 'spnn_False_0.5_4',\n",
       " 'spnn_False_0.5_5',\n",
       " 'spnn_False_0.5_6',\n",
       " 'spnn_False_0.5_7',\n",
       " 'spnn_False_0.5_8',\n",
       " 'spnn_False_0.5_9',\n",
       " 'spnn_False_1_0',\n",
       " 'spnn_False_1_1',\n",
       " 'spnn_False_1_2',\n",
       " 'spnn_False_1_3',\n",
       " 'spnn_False_1_4',\n",
       " 'spnn_False_1_5',\n",
       " 'spnn_False_1_6',\n",
       " 'spnn_False_1_7',\n",
       " 'spnn_False_1_8',\n",
       " 'spnn_False_1_9',\n",
       " 'spnn_True_0.001_0',\n",
       " 'spnn_True_0.001_1',\n",
       " 'spnn_True_0.001_2',\n",
       " 'spnn_True_0.001_3',\n",
       " 'spnn_True_0.001_4',\n",
       " 'spnn_True_0.001_5',\n",
       " 'spnn_True_0.001_6',\n",
       " 'spnn_True_0.001_7',\n",
       " 'spnn_True_0.001_8',\n",
       " 'spnn_True_0.001_9',\n",
       " 'spnn_True_0.01_0',\n",
       " 'spnn_True_0.01_1',\n",
       " 'spnn_True_0.01_2',\n",
       " 'spnn_True_0.01_3',\n",
       " 'spnn_True_0.01_4',\n",
       " 'spnn_True_0.01_5',\n",
       " 'spnn_True_0.01_6',\n",
       " 'spnn_True_0.01_7',\n",
       " 'spnn_True_0.01_8',\n",
       " 'spnn_True_0.01_9',\n",
       " 'spnn_True_0.1_0',\n",
       " 'spnn_True_0.1_1',\n",
       " 'spnn_True_0.1_2',\n",
       " 'spnn_True_0.1_3',\n",
       " 'spnn_True_0.1_4',\n",
       " 'spnn_True_0.1_5',\n",
       " 'spnn_True_0.1_6',\n",
       " 'spnn_True_0.1_7',\n",
       " 'spnn_True_0.1_8',\n",
       " 'spnn_True_0.1_9',\n",
       " 'spnn_True_0.2_0',\n",
       " 'spnn_True_0.2_1',\n",
       " 'spnn_True_0.2_2',\n",
       " 'spnn_True_0.2_3',\n",
       " 'spnn_True_0.2_4',\n",
       " 'spnn_True_0.2_5',\n",
       " 'spnn_True_0.2_6',\n",
       " 'spnn_True_0.2_7',\n",
       " 'spnn_True_0.2_8',\n",
       " 'spnn_True_0.2_9',\n",
       " 'spnn_True_0.5_0',\n",
       " 'spnn_True_0.5_1',\n",
       " 'spnn_True_0.5_2',\n",
       " 'spnn_True_0.5_3',\n",
       " 'spnn_True_0.5_4',\n",
       " 'spnn_True_0.5_5',\n",
       " 'spnn_True_0.5_6',\n",
       " 'spnn_True_0.5_7',\n",
       " 'spnn_True_0.5_8',\n",
       " 'spnn_True_0.5_9',\n",
       " 'spnn_True_1_0',\n",
       " 'spnn_True_1_1',\n",
       " 'spnn_True_1_2',\n",
       " 'spnn_True_1_3',\n",
       " 'spnn_True_1_4',\n",
       " 'spnn_True_1_5',\n",
       " 'spnn_True_1_6',\n",
       " 'spnn_True_1_7',\n",
       " 'spnn_True_1_8',\n",
       " 'spnn_True_1_9']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_file = os.listdir(f'./result/super pNN hyparam tuning/model/')\n",
    "model_file.sort()\n",
    "model_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8c370e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizations = [True, False]\n",
    "lrs = [0.001, 0.01, 0.1, 0.2, 0.5, 1]\n",
    "Results = torch.zeros([2,6,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f12550ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(len(normalizations)):\n",
    "    normalization = normalizations[n]\n",
    "    acc_factor = np.loadtxt('./result/seperate pNN/acc_factor.txt').flatten().tolist()\n",
    "    train_factor = np.loadtxt('./result/seperate pNN/train_factor.txt').flatten().tolist()\n",
    "    valid_factor = np.loadtxt('./result/seperate pNN/valid_factor.txt').flatten().tolist()\n",
    "    if not normalization:\n",
    "        train_factor = [1 for i in range(len(datasets))]\n",
    "        valid_factor = [1 for i in range(len(datasets))]\n",
    "    for lr in range(len(lrs)):\n",
    "        slr = lrs[lr]\n",
    "        for seed in range(10):\n",
    "            file_name = f'./result/super pNN hyparam tuning/model/spnn_{normalization}_{slr}_{seed}'\n",
    "            spnn = torch.load(file_name)\n",
    "            prediction_tests = spnn(X_tests) \n",
    "            tests_acc = E.ACC(prediction_tests, y_tests, acc_factor)\n",
    "            \n",
    "            Results[n, lr, seed] = tests_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ccf873b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9369, 1.0815, 1.0106, 0.8708, 0.7434, 0.6776],\n",
       "        [0.9361, 1.0751, 1.0010, 0.8542, 0.6887, 0.6006]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_mean = torch.mean(Results, dim=2)\n",
    "Results_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bbc1633c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0348, 0.0215, 0.0480, 0.0263, 0.0395, 0.1098],\n",
       "        [0.0241, 0.0220, 0.0426, 0.0345, 0.1036, 0.1260]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results_std = torch.std(Results, dim=2)\n",
    "Results_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4bc730",
   "metadata": {},
   "source": [
    "with normalization, lr=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5545e354",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_1_sep = 0.1\n",
    "loss_2_sep = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a27929",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_1 = 1.5 / loss_1_sep\n",
    "loss_2 = 2 / loss_2_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687fc47d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
